{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f24d8b6-8af8-469d-9dee-93f7a37bc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "response={'data': {'Get': {'B_ST': [{'text': 'LLaMa 3 LLaMA 3는 Meta에서 공개한 Open Source LLM model로, LLaMa2에 이어 공개된 모델이다. LLaMA 3는 Instruct Model과 Pre-trained Model에 대해 각각 8B, 70B 두 사이즈가 공개되었다. Pretraining과 Post-training 방법의 개선으로 공개된 8B, 70B의 Pretrained, Instruction-fine-tuned model이 2024 4월18일 기준 해당 parameter scale 모델 중 가장 좋은 성능을 보인다고 한다. Post-training과정에서는 false refusal rate를 줄이고, model의 alignment를 개선하고, model response의 다양성을 증가시켰다. 특히 LLaMa 3는 2보다 코드 생성, instruction 수행 능력이 크게 향상되어 모델을 보다 다양하게 활용할 수 있을 것으로 보인다. LLaMa 3 개발 시 Meta팀은 benchmark 성능 향상 뿐만 아니라 실제 추론 능력(real-world scenario) 최적화에도 집중하였다고 한다. 실제 추론 능력 검증을 위해 새로운 high-quality human evaluation set을 개발했다고 한다. 해당 데이터는 12가지 use case에 대한 총 1,800개 prompt로 구성되어 있다. (12가지 use case: asking for advice, brainstorming, classification, closed question answering, coding, creative writing, extraction, inhabiting a character/persona, open question answering, reasoning, rewriting, summarization). 아래 표는 해당 evaluation set에 대한 Claude Sonnet, Mistral Medium, GPT-3.5의 추론 결과를 비교한 것이다. https://ai.meta.com/blog/meta-llama-3/ LLaMA 3 개발팀은 모델 개발 시 Model architecture, Training data, Scaling up pretraining, Instruction fine-tuning을 중점적으로 개선했다고 한다. Model architecture',\n",
    "     'title': 'llama3'},\n",
    "    {'text': 'Llama1보다 성능 좋음 Code benchmark외 모든 benchmar에 대해 MPT보다 성능 좋음 모든 benchmark에 대해 Falcon보다 성능 좋음 LLAMA2–70B는 MMLU과 GSM8K에서 GPT-3.5에 근접한 성능을 보임 LLAMA2–70B는 모든 benchmark에서 PaLM(540B)과 비슷하거나 더 좋은 성능을 보임 LLAMA2–70B는 GPT-4와 PaLM-2-L에 비해 낮은 성능을 보임 4.2 Reward Model safety, helpfulness 모두 좋은 성능을 보인다. Reward Model 평가에는 StreamSHP-XL(FLAN-T5-xl기반), Open Assistant(DeBERTa V3 Large기반 보상모델), GPT-4(OpenAI’s API)가 사용됨 평가 결과, Meta RM이 전반적으로 높은 성능을 보이는 것으로 확인됨. 4.2 Chat Model helpfulness와 safety에 대해 chatgpt보다도 좋은 성능을 보인다. 특히 safety가 높다.(34b의 safet가 안 좋아서 공개하지 않은 거라고 한다) Reference Hugo Touvron et al.”Llama 2: Open Foundation and Fine-Tuned Chat Models,” . 2023. https://ai.meta.com/llama/ × Search',\n",
    "     'title': 'LLMA2'},\n",
    "    {'text': '[Lora/ QLora / Full Fine tune] base model: LLaMa 2 13b → qlora LLaMa 13b → lora polyglot 12.8b → full fine tune / lora polyglot 5.8b → lora polyglot 3.8b → full fine tune polyglot 1.3b → full fine tune Related Paper Review (Mistral) Related Paper Review (LLaMa 2) LLM instruction tuning [vLLM RAG + DPO + Qlora] base model: Mistral 7B SOLAR-10.7B Mixtral-8x7B [Qlora] base model: LLaMa 2 13B Related Paper Review (Mistral) Related Paper Review (LLaMa 2) 2. DATA (총 923,590개 한국어 dolly 데이터) 2.1 instruction tuning data 2.1.1 형식 {\"instruction\":instruction, \"context\": context, \"response\":response, \"category\": category} 2.1.2 instruction tuning data로 변환한 데이터 목록 KoVicuna data 구성 : ko_dataset_chatgpt(2개), ko_alpaca_style_dataset KoVicuna data to Dolly data: gpt → instruction human→ response category → open_qa',\n",
    "     'title': 'llm_tuning_merge'},\n",
    "    {'text': 'Lora 등의 기법을 사용하지 않으면 fine-tuning과 마찬가지로 모델 전체 weight가 update됨. 모델 자체가 엄청 크기 때문에 매우 많은 계산 자원과 시간이 필요하기 때문에 Lora와 같은 기법을 사용하거나 양자화를 수행하는 추세. LoRA는 모델의 특정 파라미터를 저랭크(low-rank)로 분해하여 학습하는 방법으로, 효율적으로 파라미터 수를 줄여 메모리 사용량과 계산 비용을 감소시킴.',\n",
    "     'title': 'llava'},\n",
    "    {'text': '이외에 신경망 네트워크를 이용한 모델에 대한 연구들은 다음과 같다:',\n",
    "     'title': 'TalLinzen2019'},\n",
    "    {'text': 'Illustrated by the author - Hyperparameter of Transformer 구조에 대한 이해를 돕기 위해 논문에서 설정한 Transformer의 주요 hyperparameter들에 대해 먼저 짚어보겠다. transformer encoder-decoder의 입,출력 크기는 항상 같은 차원을 지니며 내부적으로도 항상 같은 차원의 벡터가 흐르는데 이를 $d_{model}$라 부르며 논문에서는 512로 설정하였다. encoer-decoder를 여러번 수행하는데 이들의 layer 수는 6개로 설정하였다. attention연산도 병렬적으로 여러번 수행되는데 논문에서는 8개의 attention을 사용하였다. feedforward의 hidden state 크기($d_{ff}$)는 feedforward의 입출력 크기와 다르다. Feedforward의 입출력 크기는 $d_{model}$크기이지만 $d_{ff}$ 는 해당 논문에서 2048로 설정하였다.',\n",
    "     'title': 'Transformer'}]}}}\n",
    "query=\"LLaMa3에 대해 알려줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1035095-bb74-48ff-8396-3a0a631d4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "reranker_model = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True, device=\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74152517-1f90-4acb-be65-f7ced616cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = [[query, rr[\"text\"]] for rr in response[\"data\"][\"Get\"][\"B_ST\"]]\n",
    "similarity_scores = reranker_model.compute_score(sentence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d403dfa9-e655-4ea9-a447-087869d6b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_list = list(zip(similarity_scores, response[\"data\"][\"Get\"][\"B_ST\"]))\n",
    "\n",
    "paired_list.sort(key=lambda x: x[0],reverse=True)\n",
    "\n",
    "sorted_b = [item[1] for item in paired_list]\n",
    "\n",
    "response[\"data\"][\"Get\"][\"B_ST\"]=sorted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731f3d7b-30a1-4812-b3f3-e2c3082da964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reranker_fr(state):\n",
    "    print(\"---Reranking---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Rerank\n",
    "    sentence_pairs = [[question, rr[\"text\"]] for rr in documents[\"data\"][\"Get\"][\"B_ST\"]]\n",
    "    similarity_scores = reranker_model.compute_score(sentence_pairs)\n",
    "    paired_list = list(zip(similarity_scores, documents[\"data\"][\"Get\"][\"B_ST\"]))\n",
    "    paired_list.sort(key=lambda x: x[0],reverse=True)\n",
    "    sorted_b = [item[1] for item in paired_list]\n",
    "    documents[\"data\"][\"Get\"][\"B_ST\"]=sorted_b\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e9d95-fe5f-4d23-998e-6536760865a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2245d7-8740-4d2d-9b3a-401a639cdec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
