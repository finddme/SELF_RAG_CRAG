{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a33913-e363-4b4d-a539-2a3c4442512a",
   "metadata": {},
   "source": [
    "web search 방식 선정에 중요한 것은 \n",
    "어떤 web site를 각 방법들이 참조하고 있는지 아는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdadab-3d6b-4c4e-840a-5398c863279f",
   "metadata": {},
   "source": [
    "not yet : \n",
    "\n",
    "- https://generativeai.pub/make-the-web-your-best-friend-data-provider-16e1a2a31024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287670b-2342-4e2b-b232-6f3a2a2644dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eaf3ff6-bfd3-4fe5-a70d-cb6f50a471a0",
   "metadata": {},
   "source": [
    "# Tavily\n",
    "\n",
    "ref.\n",
    "\n",
    "https://docs.tavily.com/docs/tavily-api/python-sdk\n",
    "\n",
    "https://app.tavily.com/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "698eacf1-844e-4bbf-9674-fe774102682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1572d74-228c-4a7e-a94b-777a51ba44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "tavily = TavilyClient(api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf7fddc-8594-4a89-b950-abdcc02052b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tavily.search(query=\"LLaMa3 구조에 대해 알려줘\",search_depth=\"advanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb5ece6a-2d42-4fbf-9a1f-4bdc4115299a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama 3는 오픈 소스 대규모 언어 모델의 진화에서 중요한 이정표를 나타내며 성능, 기능 및 책임 있는 개발 방식의 한계를 뛰어 넘었습니다. 혁신적인 아키텍처, 대규모 훈련 데이터세트, 최첨단 미세 조정 기술을 갖춘 Llama 3는 8B 및 70B 매개변수 규모에서 LLM에 ...',\n",
       " 'GPT-4에 비견할만한 성능을 가진다는 Meta의 오픈소스 LLM Llama3를 사용해보자! Llama 3 모델 Llama 3 모델 특징8B & 70B 파라미터 규모의 모델으로, MMLU, HumanEval 등 벤치마크 태스크에서 경쟁모델보다 좋은 성능을 보임Decoder-only 트랜스포머 아키텍처를 기본으로 하되, Llama2 대비 큰 향상을 보임토큰 인코딩 ...',\n",
       " '사후 훈련 과정을 정제함으로써, llama3는 복잡한 질의에 대해 더 잘 이해하고 대응할 수 있어 출력 결과가 관련성이 있고 주제에 부합하도록 할 수 있습니다. 거짓 거절 비율을 낮추는 것은 llama3의 또 다른 주요 개선 영역입니다. 이전 언어 모델은 종종 필요한 ...',\n",
       " '라마3의 강력한 기능을 실제로 활용하고자 할 때, 다양한 방식으로 Llama3을 사용하는 방법을 참조할 수 있습니다. 이 글에서는 메타가 제공하는 서비스 외에도, 허깅페이스와 같은 오픈소스 커뮤니티를 통해 어떻게 라마3를 사용할 수 있는지 소개하고 있습니다.',\n",
       " '메타에서 최근 공개한 오픈소스 대형 언어 모델인 라마3를 다양한 방식으로 사용해보는 방법을 알아봅니다. 허깅페이스, 메타 AI 서비스, 로컬 PC 등에서 Llama3를 활용하는 방안을 소개합니다. Assistant에서 Llama3를 사용 할수 있는 방법에 대해 알아봅니다.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d[\"content\"] for d in response[\"results\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c254dc4d-59cf-44f8-b39c-2ffe58bc5888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLaMa3는 오픈 소스 대규모 언어 모델로, 혁신적인 아키텍처와 대규모 훈련 데이터세트를 특징으로 합니다. 8B 및 70B 매개변수 규모에서 작동하며, 사후 훈련 과정을 통해 복잡한 질의에 대답할 수 있고 출력 결과를 관련성 있게 제공할 수 있습니다. Meta사의 최신 오픈 소스 AI 모델인 LLaMa3은 AI 분야에서 주목받고 있습니다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.qna_search(query=\"LLaMa3 구조에 대해 알려줘\", search_depth=\"advanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bd1c8-c595-4bea-8f8f-86f54446f495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899807ef-86f1-4163-a519-8bb3ae384689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe513db3-8da2-4a6c-bb6c-576ae69a5313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c60f4bf9-b628-4538-a5a6-8610d512fc3a",
   "metadata": {},
   "source": [
    "# langchain_community\n",
    "\n",
    "ref.\n",
    "\n",
    "https://blog.gopenai.com/unleash-the-power-of-multiple-data-sources-building-advanced-rag-q-a-with-langchain-98368a084cde\n",
    "\n",
    "DUCKDUCKGO: https://python.langchain.com/v0.2/docs/integrations/tools/ddg/\n",
    "\n",
    "Wikipedia: https://python.langchain.com/v0.2/docs/integrations/tools/wikipedia/\n",
    "\n",
    "arXiv: https://python.langchain.com/v0.2/docs/integrations/tools/arxiv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fed451-0e6f-4ef2-9bd6-2b7a502a1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5f2f5-c18b-4635-b592-a148fa89883f",
   "metadata": {},
   "source": [
    "## DUCKDUCKGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73777a9b-6a43-4883-a996-3df6380553f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING DUCKDUCKGO SEARCH WRAPPER\n",
    "ddg_wrapper = DuckDuckGoSearchAPIWrapper(max_results=1)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=ddg_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cca85f9-acd0-452c-aa6b-a2489e1651db",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_res=search.run(\"LLaMa3 구조에 대해 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665bbcd6-bdff-4b43-a99c-c1f7eba04ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_res1=[]\n",
    "for s in search_res.split(\", title:\"):\n",
    "    search_res1.append(s.replace(\"[snippet: \",\"\").replace(\"]\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06525149-53dc-4fe9-ba10-e4e74e59162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama 3는 오픈 소스 대규모 언어 모델의 진화에서 중요한 이정표를 나타내며 성능, 기능 및 책임 있는 개발 방식의 한계를 뛰어 넘었습니다. 혁신적인 아키텍처, 대규모 훈련 데이터세트, 최첨단 미세 조정 기술을 갖춘 Llama 3는 8B 및 70B 매개변수 규모에서 LLM에 ...',\n",
       " ' Llama 3에 대해 알아야 할 모든 것 | 가장 강력한 오픈 소스 모델 | 사용 개념 - Unite.AI, link: https://unite.ai/ko/Lama-3에-대해-알아야-할-모든-것-가장-강력한-오픈-소스-모델이자-사용법-개념/, 메타에서 최근 공개한 오픈소스 대형 언어 모델인 라마3를 다양한 방식으로 사용해보는 방법을 알아봅니다. 허깅페이스, 메타 AI 서비스, 로컬 PC 등에서 Llama3를 활용하는 방안을 소개합니다. Assistant에서 Llama3를 사용 할수 있는 방법에 대해 알아봅니다.',\n",
       " ' 라마3 (Llama 3) 사용법: 다양한 방식으로 Llama3을 사용하는 방법 | 프롬프트해커 대니, link: https://www.magicaiprompts.com/blog/how-to-use-llama, 사후 훈련 과정을 정제함으로써, llama3는 복잡한 질의에 대해 더 잘 이해하고 대응할 수 있어 출력 결과가 관련성이 있고 주제에 부합하도록 할 수 있습니다. 거짓 거절 비율을 낮추는 것은 llama3의 또 다른 주요 개선 영역입니다. 이전 언어 모델은 종종 필요한 ...',\n",
       " ' Llama-3-8B와 Llama-3-70B: Meta의 오픈소스 LLM 모델에 대한 간략한 소개 - AI StartUps ..., link: https://cheatsheet.md/ko/llm-leaderboard/llama-3.ko, There are mainly 6 stages of how a user can interact with LlaMA 3. Stage 1 : Cater to a broad-case usage by using the model as is. Stage 2 : Use the model as per a user-defined application. Stage 3 : Use prompt-engineering to train the model to produce the desired outputs.',\n",
       " ' Deep Dive into LlaMA 3 by Hand ️ | by Srijanie Dey, PhD | Towards Data ..., link: https://towardsdatascience.com/deep-dive-into-llama-3-by-hand-️-6c6b23dc92b2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e62b54-2288-4543-9167-52018d34571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "rere=re.compile(r'/https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#()?&//=]*)/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907f62cc-0f64-4d55-b671-1977de6effb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"Llama 3에 대해 알아야 할 모든 것 | 가장 강력한 오픈 소스 모델 | 사용 개념 - Unite.AI, link: https://unite.ai/ko/Lama-3에-대해-알아야-할-모든-것-가장-강력한-오픈-소스-모델이자-사용법-개념/, 메타에서 최근 공개한 오픈소스 대형 언어 모델인 라마3를 다양한 방식으로 사용해보는 방법을 알아봅니다. 허깅페이스, 메타 AI 서비스, 로컬 PC 등에서 Llama3를 활용하는 방안을 소개합니다. Assistant에서 Llama3를 사용 할수 있는 방법에 대해 알아봅니다.\"\n",
    "rere.search(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad26203-7190-47a0-8109-a08b9cdf5358",
   "metadata": {},
   "source": [
    "## WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c3c4d4-92c0-4829-b7b7-4efe833dbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Wrapper \n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37dd6ffe-96bd-4ff6-9698-8d520d88dda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No good Wikipedia Search Result was found'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.run(\"한국 전력공사\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4813023-dc86-48a0-b0b9-892677f11beb",
   "metadata": {},
   "source": [
    "## ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98551536-1aa0-4721-b450-915aa34c3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv Wrapper\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ace2541-9854-4a16-aeb6-a8998c141268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2024-04-22\\nTitle: How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study\\nAuthors: Wei Huang, Xudong Ma, Haotong Qin, Xingyu Zheng, Chengtao Lv, Hong Chen, Jie Luo, Xiaojuan Qi, Xi'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.run(\"LLaMa3 구조에 대해 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e2d45-b148-4bd3-8687-2c567c9c569a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d2e78-6191-4f7d-aa0a-6cc0a6198441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7d92e-c78c-4048-b850-28d048224c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9cc3ab-74d9-4365-a6a7-62aa103e16e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
