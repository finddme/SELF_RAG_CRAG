{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22020f89-57ab-4474-b2fe-bf90bc9adaf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.7.1.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB SEARCH ---\n",
      "'Finished running: web_search_tavily:'\n",
      "---GENERATE Answer---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "'Finished running: generate:'\n",
      "('LLaMa3는 Meta에서 개발한 최신 오픈소스 대규모 언어 모델입니다. 이 모델은 8B 및 70B 매개변수 규모로 제공되며, 15조 '\n",
      " '토큰으로 구성된 방대한 데이터셋에서 훈련되어 Llama 2보다 약 7배 큰 데이터를 사용했습니다. LLaMa3는 혁신적인 아키텍처와 '\n",
      " '최첨단 미세 조정 기술을 통해 복잡한 질의에 대한 이해도가 높고, 관련성 있는 응답을 제공하는 등 성능과 기능 면에서 큰 향상을 '\n",
      " '보였습니다.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from rag_set.set_graph_simplify import rag_graph\n",
    "app=rag_graph()\n",
    "inputs = {\"question\": \"LLaMa3에 대해 설명해줘\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb9206-4253-4c61-9fe4-03cdca1077da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669dbb2-a81f-4f1c-8b00-40f7ceba463e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b5cc4e-3ede-404a-9b84-df4adbd509a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.7.1.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB SEARCH ---\n",
      "'Finished running: web_search_ddg:'\n",
      "---GENERATE Answer---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "'Finished running: generate:'\n",
      "---WEB SEARCH ---\n",
      "'Finished running: web_search_ddg:'\n",
      "---GENERATE Answer---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "'Finished running: generate:'\n",
      "---WEB SEARCH ---\n",
      "'Finished running: web_search_ddg:'\n",
      "---GENERATE Answer---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "'Finished running: generate:'\n",
      "---WEB SEARCH ---\n",
      "'Finished running: web_search_ddg:'\n",
      "---GENERATE Answer---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('LLaMa3는 메타가 개발한 최신 오픈소스 대규모 언어 모델로, 성능과 기능 면에서 큰 발전을 이루었습니다. 8B와 70B 파라미터 '\n",
      " '버전으로 제공되며, 15조 토큰의 방대한 데이터셋으로 훈련되어 이전 버전보다 7배 더 큰 규모의 데이터를 사용했습니다. 혁신적인 '\n",
      " '아키텍처와 최첨단 미세 조정 기술을 적용하여 다양한 활용 사례를 지원하며, 현재까지 다양한 버전의 LLaMa 모델들이 3억 건 이상 '\n",
      " '다운로드되었습니다.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from rag_set.set_graph_all import rag_graph\n",
    "app=rag_graph()\n",
    "inputs = {\"question\": \"LLaMa3에 대해 설명해줘\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2e772-bf18-4a59-a525-4318d6f17442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
